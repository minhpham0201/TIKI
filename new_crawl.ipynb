{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests \n",
    "import time\n",
    "import random\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define web url headers\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',\n",
    "    'Accept':'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8,th;q=0.7,zh-CN;q=0.6,zh;q=0.5',\n",
    "    'X-Guest-Token': 'Ae1PtIuUDbozkgpQ6VOW57jKqvchZxF2',\n",
    "    'Connection' : 'keep-alive',\n",
    "    'TE': 'Trailers'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list_url = ['https://tiki.vn/giay-the-thao-nam-co-cao/c49622',\n",
    "#             'https://tiki.vn/giay-luoi-vai-nam/c49624',\n",
    "#             'https://tiki.vn/giay-luoi-nhua-nam/c49628',\n",
    "#             'https://tiki.vn/giay-tay-nam-co-day/c49630',\n",
    "#             'https://tiki.vn/giay-sandals-nam-quai-ngang/c49634',\n",
    "#             'https://tiki.vn/giay-sandals-nam-quai-cheo/c49636',\n",
    "#             'https://tiki.vn/dep-nam-xo-ngon/c10383',\n",
    "#             'https://tiki.vn/dep-nam-di-trong-nha/c49638',\n",
    "#             'https://tiki.vn/giay-boots-nam/c8337',\n",
    "#             'https://tiki.vn/ve-sinh-giay/c49644',\n",
    "#             'https://tiki.vn/mieng-lot-giay-nam/c49646',\n",
    "#             'https://tiki.vn/phu-kien-cho-giay-nam/c49648',\n",
    "#             'https://tiki.vn/giay-the-thao-nam-co-thap/c49620',\n",
    "#             'https://tiki.vn/giay-luoi-da-nam/c49626',\n",
    "#             'https://tiki.vn/giay-tay-nam-khong-day/c49632',\n",
    "#             'https://tiki.vn/dep-nam-quai-ngang/c10384'\n",
    "#             ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl Product ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pages 22\n",
      "CATEGORY  giay-the-thao-nam-co-cao\n",
      "request done page 1\n",
      "request done page 2\n",
      "request done page 3\n",
      "request done page 4\n",
      "request done page 5\n",
      "request done page 6\n",
      "request done page 7\n",
      "request done page 8\n",
      "request done page 9\n",
      "request done page 10\n",
      "request done page 11\n",
      "request done page 12\n",
      "request done page 13\n",
      "request done page 14\n",
      "request done page 15\n",
      "request done page 16\n",
      "request done page 17\n",
      "request done page 18\n",
      "request done page 19\n",
      "request done page 20\n",
      "request done page 21\n",
      "request done page 22\n",
      "total pages 50\n",
      "CATEGORY  giay-tay-nam-khong-day\n",
      "total pages 50\n",
      "CATEGORY  dep-nam-quai-ngang\n"
     ]
    }
   ],
   "source": [
    "#create a list of URL which is all of the sub categories within a root category. Note that if a sub category already less than 50 pages\n",
    "# then I will not go deeper into its' child categories anymore\n",
    "\n",
    "list_url = ['https://tiki.vn/giay-the-thao-nam-co-cao/c49622',\n",
    "            'https://tiki.vn/giay-tay-nam-khong-day/c49632',\n",
    "            'https://tiki.vn/dep-nam-quai-ngang/c10384'\n",
    "            ]\n",
    "\n",
    "list_page_50 = []  #this list contains URL that have more than 50 pages\n",
    "for url in list_url:    #get category name and category id using urlparse lib\n",
    "    parsed_url = urlparse(url)\n",
    "    path_segments = parsed_url.path.split('/')\n",
    "\n",
    "    category_name = path_segments[1]\n",
    "    category_id = path_segments[2][1:]\n",
    "\n",
    "    product_data = []  # this list will hold data of ID, category, maximum page within category\n",
    "    page_error = []    # This list will hold data of error pages that we cannot request. So that we can crawl only \n",
    "\n",
    "    params = {                     # website url params, we will loop for different params, which means request different urls\n",
    "        'limit':'40', \n",
    "        'include': 'advertisement',\n",
    "        'aggregations': '2',\n",
    "        'trackity_id': '74634137-8702-8b12-fe42-46a46a2a2573',\n",
    "        'category': category_id,  # change based on category id\n",
    "        'page': '1',              # I set page=1, later in the loop I will change page from 1 to last_page\n",
    "        'urlKey': category_name   # change based on category name\n",
    "    }\n",
    "    \n",
    "    response = requests.get('https://tiki.vn/api/personalish/v1/blocks/listings', headers=headers, params=params)\n",
    "    last_page = response.json().get('paging').get('last_page')  # I crawl last_page from TIKI, this is important to distinguish category with less than 50 pages and category >50 pages.\n",
    "\n",
    "    print('total pages',last_page)\n",
    "    print('CATEGORY ', category_name)\n",
    "\n",
    "    if last_page == 50:           # TIKI API only allow to show 50 pages maximum. So if category with last_page = 50, we will make another list then try to use filters to divide them.  \n",
    "        list_page_50.append(url)  # Append list_page_50 the url >50 pages\n",
    "        continue \n",
    "    else:\n",
    "        for i in range(1, last_page + 1):   # Crawl from page 1 to last_page\n",
    "            params['page'] = i              # set page param to the current crawling page\n",
    "            response = requests.get('https://tiki.vn/api/personalish/v1/blocks/listings', headers=headers, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                print('request done page', i)\n",
    "                for record in response.json().get('data',[]): # this to ensure an empty if get method do not get any data inside\n",
    "                    product_id = record.get('id')\n",
    "                    product_data.append({'product_id': product_id, 'category_name': category_name, 'max_page': last_page})\n",
    "            else:\n",
    "                print('cannot request page',i)\n",
    "                page_error.append([i,category_id,category_name])  # For those pages cannot be crawled, I put it into page_error to crawl later. We must store these 3 variables to put them in to website params\n",
    "            time.sleep(random.randrange(3, 10))\n",
    "\n",
    "        # Export file\n",
    "        product_df = pd.DataFrame(product_data,columns = ['product_id','category_name','max_page'])    # Make a dataframe of crawled ID, category_name, max_page of that category\n",
    "        output_file_name = f'GIAY-NAM-{category_name}.csv'  #Export to csv file the IDs in that category. Every sub category has a distinct file. I will finally concat later in another script\n",
    "        product_df.to_csv(output_file_name)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Crawl page_error (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no error page to crawl again\n"
     ]
    }
   ],
   "source": [
    "if len(page_error) == 0:\n",
    "    print('There is no error page to crawl again')\n",
    "\n",
    "max_attempts = 3  # Maximum number of request attempts\n",
    "for param_set in page_error:\n",
    "    retry = 0  # Count for tracking the number of retry\n",
    "\n",
    "    while retry < max_attempts:\n",
    "        params = {\n",
    "            'limit': '40',\n",
    "            'include': 'advertisement',\n",
    "            'aggregations': '2',\n",
    "            'trackity_id': '74634137-8702-8b12-fe42-46a46a2a2573',\n",
    "            'category': param_set[1],\n",
    "            'page': param_set[0],\n",
    "            'urlKey': param_set[2]\n",
    "        }\n",
    "        response = requests.get('https://tiki.vn/api/personalish/v1/blocks/listings', headers=headers, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(f'Request done for page {param_set[0]}')\n",
    "            for record in response.json().get('data'):\n",
    "                product_id = record.get('id')\n",
    "                product_data.append({'product_id': product_id, 'category_name': category_name, 'max_page': last_page})\n",
    "            break  # Break the while loop early\n",
    "\n",
    "        # If still have error for this turn\n",
    "        retry += 1\n",
    "\n",
    "    # Check if the last request attempt could not request any better\n",
    "    if retry == max_attempts:\n",
    "        print(f'Reached maximum number of request attempts for the following', param_set)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl ID with 50 pages more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define price range in order to divide category with more than 50 pages into smaller groups\n",
    "price_range = [\n",
    "    '500,15000', '15001,30000', '30001,50000', '50001,80000', '80001,150000',\n",
    "    '150001,250000', '250001,350000', '350001,550000', '550000, 100000000'\n",
    "                ]\n",
    "\n",
    "list_page_50 = [] #This list will hold any category that even I have filtered already, it still have page>50. So that I can turn back again and add new price range\n",
    "\n",
    "for url in list_page_50:\n",
    "    parsed_url = urlparse(url)\n",
    "    path_segments = parsed_url.path.split('/')\n",
    "\n",
    "    category_name = path_segments[1]\n",
    "    category_id = path_segments[2][1:]\n",
    "    product_data = [] #This list hold data of products ID, Category, Max_page within that category\n",
    "    page_error = []  # This list will hold data of error pages that we cannot request. So that we can crawl again\n",
    "\n",
    "    # The code is similar to the code above, only change 1 param 'price'\n",
    "    for price in price_range: #Iterate through each price range in the list of price_range\n",
    "        params = {\n",
    "            'limit': '40',\n",
    "            'include': 'advertisement',\n",
    "            'aggregations': '2',\n",
    "            'trackity_id': '74634137-8702-8b12-fe42-46a46a2a2573',\n",
    "            'category': category_id,\n",
    "            'page': '1',\n",
    "            'urlKey': category_name,\n",
    "            'price': price\n",
    "        }\n",
    "        \n",
    "        response = requests.get('https://tiki.vn/api/personalish/v1/blocks/listings', headers=headers, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            last_page = response_json.get('paging', {}).get('last_page')\n",
    "            print('CATEGORY', category_name, price)\n",
    "            print('total pages', last_page)\n",
    "\n",
    "            if last_page == 50:\n",
    "                list_page_50.append([category_name, price])\n",
    "                continue\n",
    "            else:\n",
    "                for i in range(1, last_page + 1):\n",
    "                    params['page'] = i\n",
    "                    response = requests.get('https://tiki.vn/api/personalish/v1/blocks/listings', headers=headers,params=params)\n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        print('request done page', i)\n",
    "                        response_json = response.json()\n",
    "                        for record in response_json.get('data', []): # this to ensure an empty if get method do not get any data inside\n",
    "                            product_id = record.get('id')\n",
    "                            product_data.append({'product_id': product_id, 'category_name': category_name,\n",
    "                                                 'max_page': last_page})\n",
    "                    else:\n",
    "                        page_error.append([category_name,category_id,price,i])\n",
    "                    time.sleep(random.randrange(3, 10))\n",
    "\n",
    "    product_df = pd.DataFrame(product_data, columns=['product_id', 'category_name', 'max_page'])\n",
    "    output_file_name = f'GIAY-NU-50-{category_name}.csv'\n",
    "    product_df.to_csv(output_file_name, index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl Again for those error page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(page_error) == 0:\n",
    "    print('There is no error page to crawl again')\n",
    "\n",
    "max_attempts = 3  # Maximum number of request attempts\n",
    "for param_set in page_error:\n",
    "    retry = 0  # Count for tracking the number of retry\n",
    "\n",
    "    while retry < max_attempts:\n",
    "        params = {\n",
    "            'limit': '40',\n",
    "            'include': 'advertisement',\n",
    "            'aggregations': '2',\n",
    "            'trackity_id': '74634137-8702-8b12-fe42-46a46a2a2573',\n",
    "            'category': param_set[1],\n",
    "            'page': param_set[0],\n",
    "            'urlKey': param_set[2]\n",
    "        }\n",
    "        response = requests.get('https://tiki.vn/api/personalish/v1/blocks/listings', headers=headers, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(f'Request done for page {param_set[0]}')\n",
    "            for record in response.json().get('data'):\n",
    "                product_id = record.get('id')\n",
    "                product_data.append({'product_id': product_id, 'category_name': category_name, 'max_page': last_page})\n",
    "            break  # Break the while loop early\n",
    "\n",
    "        # If still have error for this turn\n",
    "        retry += 1\n",
    "\n",
    "    # Check if the last request attempt could not request any better\n",
    "    if retry == max_attempts:\n",
    "        print(f'Reached maximum number of request attempts for the following', param_set)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
